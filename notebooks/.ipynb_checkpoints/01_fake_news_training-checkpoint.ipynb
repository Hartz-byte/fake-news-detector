{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23e7278-6f7a-42c0-a2a0-c1f609159e1c",
   "metadata": {},
   "source": [
    "# Fake News Detection System (Without BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa63b85-27ce-4275-b623-a4d04ded493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries Import\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4d20f4-cf58-4577-aee5-ad80338f5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from data_loader import load_data\n",
    "from model_builder import build_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58966ac5-72a0-434f-ace2-440e817a9032",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset\n",
    "\n",
    "label 0 = Fake, label 1 = Real. The dataset is nearly balanced — this is good for training a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c586ec8a-86ab-4330-b35e-234bd5fd53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    23481\n",
      "1    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf01d4e-1ccf-4f81-8421-af370106fc59",
   "metadata": {},
   "source": [
    "## Train-Validation-Test Split\n",
    "\n",
    "The final splits are approximately:\n",
    "\n",
    "- 70% Train\n",
    "\n",
    "- 20% Dev\n",
    "\n",
    "- 10% Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2f53c1-4c70-4f41-8e23-e3dc48535989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 90% of data for Train+Dev, and 10% for Test\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "# Train+Dev vs Test split (90% / 10%)\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)\n",
    "\n",
    "# Train vs Dev split (70% / 20% of total)\n",
    "# X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.222, stratify=y_train_dev, random_state=42)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.475, stratify=y_train_dev, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95344637-2fca-4592-8761-4cee9f0f0ecb",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "TF-IDF vectorization turns raw text into meaningful numerical features using unigrams, bigrams, and trigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30801e53-20e3-47dc-b281-866c67d2d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000, \n",
    "    ngram_range=(1, 3), \n",
    "    min_df=3, \n",
    "    max_df=0.8, \n",
    "    stop_words='english', \n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
    "X_dev_vect = vectorizer.transform(X_dev).toarray()\n",
    "X_test_vect = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329198b2-3ddb-4097-897e-54016b9e2366",
   "metadata": {},
   "source": [
    "## Build and Train the Neural Network\n",
    "\n",
    "The model is a simple Feedforward Neural Network with regularization and dropout. The class_weight addresses slight label imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38276c11-9c2b-4962-9e42-c032b11e4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7128 - loss: 3.1646 - val_accuracy: 0.9385 - val_loss: 0.6715\n",
      "Epoch 2/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.6960 - val_accuracy: 0.9511 - val_loss: 0.6553\n",
      "Epoch 3/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9190 - loss: 0.6812 - val_accuracy: 0.9541 - val_loss: 0.6401\n",
      "Epoch 4/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9228 - loss: 0.6660 - val_accuracy: 0.9533 - val_loss: 0.6245\n",
      "Epoch 5/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.6477 - val_accuracy: 0.9550 - val_loss: 0.6087\n",
      "Epoch 6/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9295 - loss: 0.6343 - val_accuracy: 0.9576 - val_loss: 0.5921\n",
      "Epoch 7/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.6165 - val_accuracy: 0.9606 - val_loss: 0.5773\n",
      "Epoch 8/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.6017 - val_accuracy: 0.9635 - val_loss: 0.5616\n",
      "Epoch 9/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9416 - loss: 0.5848 - val_accuracy: 0.9584 - val_loss: 0.5485\n",
      "Epoch 10/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9442 - loss: 0.5688 - val_accuracy: 0.9612 - val_loss: 0.5338\n",
      "Epoch 11/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9484 - loss: 0.5554 - val_accuracy: 0.9686 - val_loss: 0.5198\n",
      "Epoch 12/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9479 - loss: 0.5451 - val_accuracy: 0.9682 - val_loss: 0.5069\n",
      "Epoch 13/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9489 - loss: 0.5320 - val_accuracy: 0.9636 - val_loss: 0.4965\n",
      "Epoch 14/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9502 - loss: 0.5175 - val_accuracy: 0.9666 - val_loss: 0.4839\n",
      "Epoch 15/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9490 - loss: 0.5094 - val_accuracy: 0.9680 - val_loss: 0.4719\n",
      "Epoch 16/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9513 - loss: 0.4948 - val_accuracy: 0.9699 - val_loss: 0.4619\n",
      "Epoch 17/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9555 - loss: 0.4856 - val_accuracy: 0.9710 - val_loss: 0.4503\n",
      "Epoch 18/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9578 - loss: 0.4727 - val_accuracy: 0.9729 - val_loss: 0.4403\n",
      "Epoch 19/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9587 - loss: 0.4652 - val_accuracy: 0.9743 - val_loss: 0.4309\n",
      "Epoch 20/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9617 - loss: 0.4539 - val_accuracy: 0.9741 - val_loss: 0.4217\n",
      "Epoch 21/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.4448 - val_accuracy: 0.9734 - val_loss: 0.4140\n",
      "Epoch 22/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9606 - loss: 0.4390 - val_accuracy: 0.9746 - val_loss: 0.4045\n",
      "Epoch 23/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.4321 - val_accuracy: 0.9761 - val_loss: 0.3965\n",
      "Epoch 24/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9619 - loss: 0.4198 - val_accuracy: 0.9743 - val_loss: 0.3894\n",
      "Epoch 25/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9645 - loss: 0.4129 - val_accuracy: 0.9759 - val_loss: 0.3814\n",
      "Epoch 26/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9667 - loss: 0.4022 - val_accuracy: 0.9774 - val_loss: 0.3743\n",
      "Epoch 27/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9651 - loss: 0.3987 - val_accuracy: 0.9776 - val_loss: 0.3668\n",
      "Epoch 28/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9680 - loss: 0.3923 - val_accuracy: 0.9785 - val_loss: 0.3600\n",
      "Epoch 29/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9643 - loss: 0.3853 - val_accuracy: 0.9783 - val_loss: 0.3532\n",
      "Epoch 30/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.3799 - val_accuracy: 0.9786 - val_loss: 0.3481\n",
      "Epoch 31/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.3708 - val_accuracy: 0.9782 - val_loss: 0.3423\n",
      "Epoch 32/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9702 - loss: 0.3658 - val_accuracy: 0.9803 - val_loss: 0.3359\n",
      "Epoch 33/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.3591 - val_accuracy: 0.9798 - val_loss: 0.3302\n",
      "Epoch 34/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9707 - loss: 0.3523 - val_accuracy: 0.9809 - val_loss: 0.3241\n",
      "Epoch 35/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.3484 - val_accuracy: 0.9805 - val_loss: 0.3197\n",
      "Epoch 36/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9712 - loss: 0.3453 - val_accuracy: 0.9787 - val_loss: 0.3159\n",
      "Epoch 37/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9721 - loss: 0.3382 - val_accuracy: 0.9800 - val_loss: 0.3107\n",
      "Epoch 38/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9707 - loss: 0.3328 - val_accuracy: 0.9818 - val_loss: 0.3056\n",
      "Epoch 39/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.3286 - val_accuracy: 0.9823 - val_loss: 0.3006\n",
      "Epoch 40/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9749 - loss: 0.3256 - val_accuracy: 0.9821 - val_loss: 0.2961\n",
      "Epoch 41/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.3193 - val_accuracy: 0.9812 - val_loss: 0.2923\n",
      "Epoch 42/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.3167 - val_accuracy: 0.9825 - val_loss: 0.2874\n",
      "Epoch 43/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.3127 - val_accuracy: 0.9812 - val_loss: 0.2849\n",
      "Epoch 44/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9752 - loss: 0.3048 - val_accuracy: 0.9836 - val_loss: 0.2805\n",
      "Epoch 45/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9770 - loss: 0.3024 - val_accuracy: 0.9832 - val_loss: 0.2772\n",
      "Epoch 46/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.2979 - val_accuracy: 0.9822 - val_loss: 0.2727\n",
      "Epoch 47/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.2964 - val_accuracy: 0.9824 - val_loss: 0.2686\n",
      "Epoch 48/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9751 - loss: 0.2920 - val_accuracy: 0.9832 - val_loss: 0.2661\n",
      "Epoch 49/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9747 - loss: 0.2900 - val_accuracy: 0.9836 - val_loss: 0.2633\n",
      "Epoch 50/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9797 - loss: 0.2834 - val_accuracy: 0.9845 - val_loss: 0.2595\n",
      "Epoch 51/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9793 - loss: 0.2800 - val_accuracy: 0.9844 - val_loss: 0.2561\n",
      "Epoch 52/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.2776 - val_accuracy: 0.9848 - val_loss: 0.2523\n",
      "Epoch 53/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.2744 - val_accuracy: 0.9850 - val_loss: 0.2509\n",
      "Epoch 54/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.2730 - val_accuracy: 0.9857 - val_loss: 0.2473\n",
      "Epoch 55/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.2676 - val_accuracy: 0.9858 - val_loss: 0.2442\n",
      "Epoch 56/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.2681 - val_accuracy: 0.9858 - val_loss: 0.2421\n",
      "Epoch 57/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.2621 - val_accuracy: 0.9857 - val_loss: 0.2393\n",
      "Epoch 58/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.2602 - val_accuracy: 0.9868 - val_loss: 0.2360\n",
      "Epoch 59/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.2590 - val_accuracy: 0.9868 - val_loss: 0.2353\n",
      "Epoch 60/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.2551 - val_accuracy: 0.9843 - val_loss: 0.2321\n",
      "Epoch 61/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9790 - loss: 0.2528 - val_accuracy: 0.9868 - val_loss: 0.2297\n",
      "Epoch 62/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.2497 - val_accuracy: 0.9860 - val_loss: 0.2276\n",
      "Epoch 63/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.2469 - val_accuracy: 0.9879 - val_loss: 0.2248\n",
      "Epoch 64/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.2468 - val_accuracy: 0.9868 - val_loss: 0.2220\n",
      "Epoch 65/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.2416 - val_accuracy: 0.9865 - val_loss: 0.2195\n",
      "Epoch 66/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9806 - loss: 0.2400 - val_accuracy: 0.9886 - val_loss: 0.2179\n",
      "Epoch 67/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.2417 - val_accuracy: 0.9850 - val_loss: 0.2168\n",
      "Epoch 68/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.2377 - val_accuracy: 0.9879 - val_loss: 0.2134\n",
      "Epoch 69/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9833 - loss: 0.2326 - val_accuracy: 0.9875 - val_loss: 0.2118\n",
      "Epoch 70/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.2301 - val_accuracy: 0.9887 - val_loss: 0.2102\n",
      "Epoch 71/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9824 - loss: 0.2325 - val_accuracy: 0.9874 - val_loss: 0.2088\n",
      "Epoch 72/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.2297 - val_accuracy: 0.9877 - val_loss: 0.2052\n",
      "Epoch 73/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.2264 - val_accuracy: 0.9883 - val_loss: 0.2043\n",
      "Epoch 74/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.2252 - val_accuracy: 0.9881 - val_loss: 0.2025\n",
      "Epoch 75/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.2211 - val_accuracy: 0.9887 - val_loss: 0.2005\n",
      "Epoch 76/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.2199 - val_accuracy: 0.9882 - val_loss: 0.1990\n",
      "Epoch 77/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9811 - loss: 0.2196 - val_accuracy: 0.9880 - val_loss: 0.1979\n",
      "Epoch 78/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9824 - loss: 0.2186 - val_accuracy: 0.9892 - val_loss: 0.1964\n",
      "Epoch 79/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.2158 - val_accuracy: 0.9876 - val_loss: 0.1953\n",
      "Epoch 80/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9842 - loss: 0.2132 - val_accuracy: 0.9891 - val_loss: 0.1947\n",
      "Epoch 81/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.2110 - val_accuracy: 0.9890 - val_loss: 0.1911\n",
      "Epoch 82/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.2083 - val_accuracy: 0.9891 - val_loss: 0.1902\n",
      "Epoch 83/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.2076 - val_accuracy: 0.9886 - val_loss: 0.1882\n",
      "Epoch 84/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9846 - loss: 0.2082 - val_accuracy: 0.9895 - val_loss: 0.1863\n",
      "Epoch 85/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9831 - loss: 0.2083 - val_accuracy: 0.9893 - val_loss: 0.1862\n",
      "Epoch 86/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9848 - loss: 0.2052 - val_accuracy: 0.9879 - val_loss: 0.1872\n",
      "Epoch 87/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9845 - loss: 0.2036 - val_accuracy: 0.9894 - val_loss: 0.1826\n",
      "Epoch 88/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.2024 - val_accuracy: 0.9898 - val_loss: 0.1818\n",
      "Epoch 89/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9860 - loss: 0.1989 - val_accuracy: 0.9899 - val_loss: 0.1810\n",
      "Epoch 90/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9850 - loss: 0.1988 - val_accuracy: 0.9895 - val_loss: 0.1796\n",
      "Epoch 91/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.1967 - val_accuracy: 0.9902 - val_loss: 0.1799\n",
      "Epoch 92/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.1973 - val_accuracy: 0.9897 - val_loss: 0.1769\n",
      "Epoch 93/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9847 - loss: 0.1940 - val_accuracy: 0.9893 - val_loss: 0.1760\n",
      "Epoch 94/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.1931 - val_accuracy: 0.9898 - val_loss: 0.1750\n",
      "Epoch 95/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9853 - loss: 0.1929 - val_accuracy: 0.9898 - val_loss: 0.1737\n",
      "Epoch 96/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.1893 - val_accuracy: 0.9882 - val_loss: 0.1734\n",
      "Epoch 97/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9869 - loss: 0.1877 - val_accuracy: 0.9900 - val_loss: 0.1711\n",
      "Epoch 98/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.1918 - val_accuracy: 0.9901 - val_loss: 0.1705\n",
      "Epoch 99/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9881 - loss: 0.1870 - val_accuracy: 0.9904 - val_loss: 0.1694\n",
      "Epoch 100/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.1848 - val_accuracy: 0.9902 - val_loss: 0.1674\n",
      "Epoch 101/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.1841 - val_accuracy: 0.9908 - val_loss: 0.1672\n",
      "Epoch 102/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.1836 - val_accuracy: 0.9906 - val_loss: 0.1658\n",
      "Epoch 103/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.1824 - val_accuracy: 0.9906 - val_loss: 0.1656\n",
      "Epoch 104/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.1841 - val_accuracy: 0.9893 - val_loss: 0.1650\n",
      "Epoch 105/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9870 - loss: 0.1837 - val_accuracy: 0.9897 - val_loss: 0.1635\n",
      "Epoch 106/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.1775 - val_accuracy: 0.9894 - val_loss: 0.1644\n",
      "Epoch 107/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.1775 - val_accuracy: 0.9895 - val_loss: 0.1613\n",
      "Epoch 108/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9859 - loss: 0.1799 - val_accuracy: 0.9907 - val_loss: 0.1587\n",
      "Epoch 109/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.1797 - val_accuracy: 0.9907 - val_loss: 0.1588\n",
      "Epoch 110/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.1740 - val_accuracy: 0.9909 - val_loss: 0.1593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1eac7f05f30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the model\n",
    "model = build_model(input_dim=X_train_vect.shape[1])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_vect, y_train,\n",
    "    validation_data=(X_dev_vect, y_dev),\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight = {0: 1.0, 1: 1.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec62249-fc84-4cd7-91cb-544919cb0173",
   "metadata": {},
   "source": [
    "## Evaluate on Test Set\n",
    "\n",
    "Final test accuracy is ~99%, indicating strong generalization on in-distribution test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d8db63-3364-41ee-94c3-fce9c19244da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2348\n",
      "           1       0.98      0.99      0.99      2142\n",
      "\n",
      "    accuracy                           0.99      4490\n",
      "   macro avg       0.99      0.99      0.99      4490\n",
      "weighted avg       0.99      0.99      0.99      4490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Testing Loop — Evaluation on Test Set\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "y_pred_prob = model.predict(X_test_vect)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc294d-defe-4953-8588-77d1d4898c9c",
   "metadata": {},
   "source": [
    "## Save and Reload Model + Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ccaef8-ee07-4350-9599-e668ed285bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/vectorizer.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and vectorizer\n",
    "model.save(\"../models/model.keras\")\n",
    "joblib.dump(vectorizer, \"../models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37df833b-9b2c-46ff-8876-b1570567716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for inference\n",
    "model = load_model(\"../models/model.keras\")\n",
    "vectorizer = joblib.load(\"../models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec46505-29fb-45c0-81f4-97da602e6711",
   "metadata": {},
   "source": [
    "## Real-world Inference Examples\n",
    "\n",
    "The model sometimes mislabels real-looking headlines as fake. This is a known limitation of shallow models like TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ff5a98-b255-4c4d-9a96-b6192050bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference on Real-world Samples:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Breaking: Prime Minister announces new economic reforms. -> Real (0.55)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Aliens landed in Ohio according to anonymous sources. -> Fake (0.05)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "The COVID-19 vaccine rollout continues across Europe. -> Fake (0.07)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "NASA confirms water on the Moon. -> Fake (0.12)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Donald Trump wins the presidential election again. -> Real (0.57)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "India is a country. -> Fake (0.13)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "White House, Congress prepare for talks on spending, immigration -> Fake (0.33)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Scientists discover a way to live forever using jellyfish DNA. -> Fake (0.06)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Stocks crash after rumors of global economic collapse. -> Fake (0.19)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "New study shows chocolate improves brain function. -> Fake (0.09)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Vaccine causes telepathic powers in 1% of recipients, claims study. -> Fake (0.09)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "UN convenes emergency session on climate change crisis. -> Fake (0.14)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Elon Musk launches reusable rocket that lands on Mars. -> Fake (0.14)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Government passes bill banning all smartphones by 2025. -> Fake (0.24)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Earthquake hits Tokyo, no casualties reported. -> Fake (0.17)\n"
     ]
    }
   ],
   "source": [
    "# Real-world examples\n",
    "print(\"\\nInference on Real-world Samples:\")\n",
    "\n",
    "examples = [\n",
    "    (\"Breaking: Prime Minister announces new economic reforms.\", \"politicsNews\"),  # Real\n",
    "    (\"Aliens landed in Ohio according to anonymous sources.\", \"worldnews\"),        # Fake\n",
    "    (\"The COVID-19 vaccine rollout continues across Europe.\", \"healthNews\"),       # Real\n",
    "    (\"NASA confirms water on the Moon.\", \"scienceNews\"),                           # Real\n",
    "    (\"Donald Trump wins the presidential election again.\", \"politicsNews\"),        # Fake/Unlikely\n",
    "    (\"India is a country.\", \"worldnews\"),                                          # Generic/ambiguous\n",
    "    (\"White House, Congress prepare for talks on spending, immigration\", \"politicsNews\"),  # Real\n",
    "    (\"Scientists discover a way to live forever using jellyfish DNA.\", \"scienceNews\"),     # Likely Fake\n",
    "    (\"Stocks crash after rumors of global economic collapse.\", \"businessNews\"),            # Possibly Fake\n",
    "    (\"New study shows chocolate improves brain function.\", \"healthNews\"),                  # Real-sounding\n",
    "    (\"Vaccine causes telepathic powers in 1% of recipients, claims study.\", \"healthNews\"), # Fake\n",
    "    (\"UN convenes emergency session on climate change crisis.\", \"worldnews\"),             # Real\n",
    "    (\"Elon Musk launches reusable rocket that lands on Mars.\", \"scienceNews\"),            # Partially Fake (as of now)\n",
    "    (\"Government passes bill banning all smartphones by 2025.\", \"politicsNews\"),          # Likely Fake\n",
    "    (\"Earthquake hits Tokyo, no casualties reported.\", \"worldnews\")                       # Real\n",
    "]\n",
    "\n",
    "\n",
    "for title, subject in examples:\n",
    "    combined_text = f\"{title} [SEP] {subject}\"\n",
    "    X_ex = vectorizer.transform([combined_text])\n",
    "    pred_prob = model.predict(X_ex.toarray())[0][0]\n",
    "\n",
    "    # Use threshold tuned on dev set if available, else fallback\n",
    "    threshold = 0.4  \n",
    "    label = \"Real\" if pred_prob >= threshold else \"Fake\"\n",
    "\n",
    "    print(f\"{title} -> {label} ({pred_prob:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606b577e-cbc3-421d-9b2f-2dce8d64ee76",
   "metadata": {},
   "source": [
    "## Classification Report for All Splits\n",
    "\n",
    "All splits report ~99% precision, recall, and F1 — suggesting very strong consistency across data splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18639ab3-ac7e-4bf2-840e-8f6bbf1c7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 755us/step\n",
      "\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     11095\n",
      "           1       0.99      0.99      0.99     10119\n",
      "\n",
      "    accuracy                           0.99     21214\n",
      "   macro avg       0.99      0.99      0.99     21214\n",
      "weighted avg       0.99      0.99      0.99     21214\n",
      "\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 721us/step\n",
      "\n",
      "Dev Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     10038\n",
      "           1       0.99      0.99      0.99      9156\n",
      "\n",
      "    accuracy                           0.99     19194\n",
      "   macro avg       0.99      0.99      0.99     19194\n",
      "weighted avg       0.99      0.99      0.99     19194\n",
      "\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2348\n",
      "           1       0.98      0.99      0.99      2142\n",
      "\n",
      "    accuracy                           0.99      4490\n",
      "   macro avg       0.99      0.99      0.99      4490\n",
      "weighted avg       0.99      0.99      0.99      4490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "y_train_pred = (model.predict(X_train_vect) > 0.5).astype(int)\n",
    "print(\"\\nTrain Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Dev\n",
    "y_dev_pred = (model.predict(X_dev_vect) > 0.5).astype(int)\n",
    "print(\"\\nDev Classification Report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "# Test\n",
    "y_test_pred = (model.predict(X_test_vect) > 0.5).astype(int)\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3ee8ab-cae7-435a-a1af-4c9953d54027",
   "metadata": {},
   "source": [
    "## Feature Exploration\n",
    "\n",
    "Inspecting TF-IDF vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6368d0-8386-4eec-932f-d3b7285c5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample features:\n",
      "['00' '000' '000 people' '10' '10 000' '10 percent' '10 years' '100'\n",
      " '100 000' '11' '12' '120' '13' '14' '15' '150' '16' '17' '18' '19']\n",
      "Total features in vocab: 5000\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSample features:\")\n",
    "print(vectorizer.get_feature_names_out()[:20])\n",
    "print(\"Total features in vocab:\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe3101-ae60-455e-b28a-469e5bd21e70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
