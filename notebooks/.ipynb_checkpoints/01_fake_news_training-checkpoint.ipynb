{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa63b85-27ce-4275-b623-a4d04ded493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e4d20f4-cf58-4577-aee5-ad80338f5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from data_loader import load_data\n",
    "from model_builder import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c586ec8a-86ab-4330-b35e-234bd5fd53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    23481\n",
      "1    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "# Use 'text' as input and 'label' as target\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c2f53c1-4c70-4f41-8e23-e3dc48535989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train+Dev vs Test split (90% / 10%)\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "368aead6-31fc-493a-ac65-72a2cd3492fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vs Dev split (70% / 15% of total)\n",
    "# X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.222, stratify=y_train_dev, random_state=42)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.475, stratify=y_train_dev, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30801e53-20e3-47dc-b281-866c67d2d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000, \n",
    "    ngram_range=(1, 3), \n",
    "    min_df=3, \n",
    "    max_df=0.8, \n",
    "    stop_words='english', \n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
    "X_dev_vect = vectorizer.transform(X_dev).toarray()\n",
    "X_test_vect = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96789b43-d589-429e-b0ac-a643429b1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_model(input_dim=X_train_vect.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f158563-849b-4296-9f0d-ec2c5b188d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38276c11-9c2b-4962-9e42-c032b11e4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.2810 - val_accuracy: 0.9849 - val_loss: 0.2555\n",
      "Epoch 2/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.2773 - val_accuracy: 0.9853 - val_loss: 0.2524\n",
      "Epoch 3/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9769 - loss: 0.2768 - val_accuracy: 0.9858 - val_loss: 0.2499\n",
      "Epoch 4/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.2698 - val_accuracy: 0.9861 - val_loss: 0.2464\n",
      "Epoch 5/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.2689 - val_accuracy: 0.9853 - val_loss: 0.2432\n",
      "Epoch 6/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.2621 - val_accuracy: 0.9853 - val_loss: 0.2425\n",
      "Epoch 7/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9773 - loss: 0.2674 - val_accuracy: 0.9853 - val_loss: 0.2386\n",
      "Epoch 8/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9801 - loss: 0.2589 - val_accuracy: 0.9869 - val_loss: 0.2361\n",
      "Epoch 9/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9789 - loss: 0.2576 - val_accuracy: 0.9863 - val_loss: 0.2345\n",
      "Epoch 10/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9791 - loss: 0.2553 - val_accuracy: 0.9868 - val_loss: 0.2320\n",
      "Epoch 11/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.2532 - val_accuracy: 0.9859 - val_loss: 0.2309\n",
      "Epoch 12/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9801 - loss: 0.2484 - val_accuracy: 0.9868 - val_loss: 0.2255\n",
      "Epoch 13/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.2450 - val_accuracy: 0.9867 - val_loss: 0.2237\n",
      "Epoch 14/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.2479 - val_accuracy: 0.9869 - val_loss: 0.2219\n",
      "Epoch 15/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.2434 - val_accuracy: 0.9875 - val_loss: 0.2192\n",
      "Epoch 16/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.2431 - val_accuracy: 0.9863 - val_loss: 0.2185\n",
      "Epoch 17/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9810 - loss: 0.2392 - val_accuracy: 0.9878 - val_loss: 0.2154\n",
      "Epoch 18/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9830 - loss: 0.2350 - val_accuracy: 0.9875 - val_loss: 0.2126\n",
      "Epoch 19/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.2347 - val_accuracy: 0.9873 - val_loss: 0.2125\n",
      "Epoch 20/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9837 - loss: 0.2332 - val_accuracy: 0.9861 - val_loss: 0.2113\n",
      "Epoch 21/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9828 - loss: 0.2302 - val_accuracy: 0.9875 - val_loss: 0.2074\n",
      "Epoch 22/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9827 - loss: 0.2292 - val_accuracy: 0.9865 - val_loss: 0.2065\n",
      "Epoch 23/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.2270 - val_accuracy: 0.9878 - val_loss: 0.2042\n",
      "Epoch 24/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.2214 - val_accuracy: 0.9883 - val_loss: 0.2033\n",
      "Epoch 25/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9822 - loss: 0.2245 - val_accuracy: 0.9890 - val_loss: 0.2003\n",
      "Epoch 26/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.2198 - val_accuracy: 0.9879 - val_loss: 0.1989\n",
      "Epoch 27/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.2192 - val_accuracy: 0.9890 - val_loss: 0.1968\n",
      "Epoch 28/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9830 - loss: 0.2185 - val_accuracy: 0.9888 - val_loss: 0.1955\n",
      "Epoch 29/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.2153 - val_accuracy: 0.9887 - val_loss: 0.1943\n",
      "Epoch 30/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.2160 - val_accuracy: 0.9868 - val_loss: 0.1935\n",
      "Epoch 31/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.2119 - val_accuracy: 0.9891 - val_loss: 0.1916\n",
      "Epoch 32/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.2089 - val_accuracy: 0.9893 - val_loss: 0.1904\n",
      "Epoch 33/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9839 - loss: 0.2113 - val_accuracy: 0.9889 - val_loss: 0.1882\n",
      "Epoch 34/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.2060 - val_accuracy: 0.9885 - val_loss: 0.1878\n",
      "Epoch 35/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.2054 - val_accuracy: 0.9893 - val_loss: 0.1847\n",
      "Epoch 36/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9851 - loss: 0.2024 - val_accuracy: 0.9875 - val_loss: 0.1840\n",
      "Epoch 37/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.2001 - val_accuracy: 0.9885 - val_loss: 0.1835\n",
      "Epoch 38/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.2014 - val_accuracy: 0.9884 - val_loss: 0.1814\n",
      "Epoch 39/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.1984 - val_accuracy: 0.9898 - val_loss: 0.1812\n",
      "Epoch 40/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.1984 - val_accuracy: 0.9905 - val_loss: 0.1787\n",
      "Epoch 41/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9866 - loss: 0.1966 - val_accuracy: 0.9898 - val_loss: 0.1778\n",
      "Epoch 42/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9873 - loss: 0.1925 - val_accuracy: 0.9893 - val_loss: 0.1759\n",
      "Epoch 43/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.1937 - val_accuracy: 0.9879 - val_loss: 0.1770\n",
      "Epoch 44/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.1931 - val_accuracy: 0.9902 - val_loss: 0.1735\n",
      "Epoch 45/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.1909 - val_accuracy: 0.9905 - val_loss: 0.1734\n",
      "Epoch 46/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.1910 - val_accuracy: 0.9877 - val_loss: 0.1737\n",
      "Epoch 47/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9869 - loss: 0.1877 - val_accuracy: 0.9885 - val_loss: 0.1727\n",
      "Epoch 48/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.1885 - val_accuracy: 0.9897 - val_loss: 0.1677\n",
      "Epoch 49/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.1867 - val_accuracy: 0.9899 - val_loss: 0.1697\n",
      "Epoch 50/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.1836 - val_accuracy: 0.9905 - val_loss: 0.1682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22d0f09b880>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_vect, y_train,\n",
    "    validation_data=(X_dev_vect, y_dev),\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight = {0: 1.0, 1: 1.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71d8db63-3364-41ee-94c3-fce9c19244da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2348\n",
      "           1       0.97      0.99      0.98      2142\n",
      "\n",
      "    accuracy                           0.98      4490\n",
      "   macro avg       0.98      0.98      0.98      4490\n",
      "weighted avg       0.98      0.98      0.98      4490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Testing Loop — Evaluation on Test Set\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "y_pred_prob = model.predict(X_test_vect)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75ccaef8-ee07-4350-9599-e668ed285bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/vectorizer.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and vectorizer\n",
    "model.save(\"../models/model.keras\")\n",
    "joblib.dump(vectorizer, \"../models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37df833b-9b2c-46ff-8876-b1570567716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for inference\n",
    "model = load_model(\"../models/model.keras\")\n",
    "vectorizer = joblib.load(\"../models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ff5a98-b255-4c4d-9a96-b6192050bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference on Real-world Samples:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "Breaking: Prime Minister announces new economic reforms. -> Real (0.70)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Aliens landed in Ohio according to anonymous sources. -> Fake (0.17)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "The COVID-19 vaccine rollout continues across Europe. -> Fake (0.22)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "NASA confirms water on the Moon. -> Fake (0.26)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Donald Trump wins the presidential election again. -> Real (0.55)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "India is a country. -> Fake (0.28)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "White House, Congress prepare for talks on spending, immigration -> Real (0.48)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Scientists discover a way to live forever using jellyfish DNA. -> Fake (0.16)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Stocks crash after rumors of global economic collapse. -> Fake (0.35)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "New study shows chocolate improves brain function. -> Fake (0.22)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Vaccine causes telepathic powers in 1% of recipients, claims study. -> Fake (0.23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "UN convenes emergency session on climate change crisis. -> Fake (0.29)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Elon Musk launches reusable rocket that lands on Mars. -> Fake (0.25)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Government passes bill banning all smartphones by 2025. -> Real (0.41)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Earthquake hits Tokyo, no casualties reported. -> Fake (0.32)\n",
      "\n",
      "Sample features:\n",
      "['00' '000' '000 people' '10' '10 000' '10 percent' '10 years' '100'\n",
      " '100 000' '11' '12' '120' '13' '14' '15' '150' '16' '17' '18' '19']\n",
      "Total features in vocab: 5000\n"
     ]
    }
   ],
   "source": [
    "# Real-world examples\n",
    "print(\"\\nInference on Real-world Samples:\")\n",
    "\n",
    "examples = [\n",
    "    (\"Breaking: Prime Minister announces new economic reforms.\", \"politicsNews\"),  # Real\n",
    "    (\"Aliens landed in Ohio according to anonymous sources.\", \"worldnews\"),        # Fake\n",
    "    (\"The COVID-19 vaccine rollout continues across Europe.\", \"healthNews\"),       # Real\n",
    "    (\"NASA confirms water on the Moon.\", \"scienceNews\"),                           # Real\n",
    "    (\"Donald Trump wins the presidential election again.\", \"politicsNews\"),        # Fake/Unlikely\n",
    "    (\"India is a country.\", \"worldnews\"),                                          # Generic/ambiguous\n",
    "    (\"White House, Congress prepare for talks on spending, immigration\", \"politicsNews\"),  # Real\n",
    "    (\"Scientists discover a way to live forever using jellyfish DNA.\", \"scienceNews\"),     # Likely Fake\n",
    "    (\"Stocks crash after rumors of global economic collapse.\", \"businessNews\"),            # Possibly Fake\n",
    "    (\"New study shows chocolate improves brain function.\", \"healthNews\"),                  # Real-sounding\n",
    "    (\"Vaccine causes telepathic powers in 1% of recipients, claims study.\", \"healthNews\"), # Fake\n",
    "    (\"UN convenes emergency session on climate change crisis.\", \"worldnews\"),             # Real\n",
    "    (\"Elon Musk launches reusable rocket that lands on Mars.\", \"scienceNews\"),            # Partially Fake (as of now)\n",
    "    (\"Government passes bill banning all smartphones by 2025.\", \"politicsNews\"),          # Likely Fake\n",
    "    (\"Earthquake hits Tokyo, no casualties reported.\", \"worldnews\")                       # Real\n",
    "]\n",
    "\n",
    "\n",
    "for title, subject in examples:\n",
    "    combined_text = f\"{title} [SEP] {subject}\"\n",
    "    X_ex = vectorizer.transform([combined_text])\n",
    "    pred_prob = model.predict(X_ex.toarray())[0][0]\n",
    "\n",
    "    # Use threshold tuned on dev set if available, else fallback\n",
    "    threshold = 0.4  \n",
    "    label = \"Real\" if pred_prob >= threshold else \"Fake\"\n",
    "\n",
    "    print(f\"{title} -> {label} ({pred_prob:.2f})\")\n",
    "\n",
    "# Check vocab info\n",
    "print(\"\\nSample features:\")\n",
    "print(vectorizer.get_feature_names_out()[:20])\n",
    "print(\"Total features in vocab:\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18639ab3-ac7e-4bf2-840e-8f6bbf1c7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step\n",
      "\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     11095\n",
      "           1       0.98      0.99      0.98     10119\n",
      "\n",
      "    accuracy                           0.99     21214\n",
      "   macro avg       0.98      0.99      0.99     21214\n",
      "weighted avg       0.99      0.99      0.99     21214\n",
      "\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step\n",
      "\n",
      "Dev Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99     10038\n",
      "           1       0.97      0.99      0.98      9156\n",
      "\n",
      "    accuracy                           0.98     19194\n",
      "   macro avg       0.98      0.98      0.98     19194\n",
      "weighted avg       0.98      0.98      0.98     19194\n",
      "\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      2348\n",
      "           1       0.97      0.99      0.98      2142\n",
      "\n",
      "    accuracy                           0.98      4490\n",
      "   macro avg       0.98      0.98      0.98      4490\n",
      "weighted avg       0.98      0.98      0.98      4490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train predictions\n",
    "y_train_pred = (model.predict(X_train_vect) > 0.5).astype(int)\n",
    "print(\"\\nTrain Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Dev predictions\n",
    "y_dev_pred = (model.predict(X_dev_vect) > 0.5).astype(int)\n",
    "print(\"\\nDev Classification Report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "# Test predictions\n",
    "y_test_pred = (model.predict(X_test_vect) > 0.5).astype(int)\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca7d45-ea49-40de-b2ab-7015a99430d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
