{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efa63b85-27ce-4275-b623-a4d04ded493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e4d20f4-cf58-4577-aee5-ad80338f5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "import joblib\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "from data_loader import load_data\n",
    "from model_builder import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c586ec8a-86ab-4330-b35e-234bd5fd53df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    23481\n",
      "1    21417\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = load_data()\n",
    "\n",
    "# Use 'text' as input and 'label' as target\n",
    "X = df['text']\n",
    "y = df['label']\n",
    "\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c2f53c1-4c70-4f41-8e23-e3dc48535989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train+Dev vs Test split (90% / 10%)\n",
    "X_train_dev, X_test, y_train_dev, y_test = train_test_split(X, y, test_size=0.10, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368aead6-31fc-493a-ac65-72a2cd3492fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train vs Dev split (70% / 15% of total)\n",
    "# X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.222, stratify=y_train_dev, random_state=42)\n",
    "\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train_dev, y_train_dev, test_size=0.475, stratify=y_train_dev, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30801e53-20e3-47dc-b281-866c67d2d54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=5000, \n",
    "    ngram_range=(1, 3), \n",
    "    min_df=3, \n",
    "    max_df=0.8, \n",
    "    stop_words='english', \n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "X_train_vect = vectorizer.fit_transform(X_train).toarray()\n",
    "X_dev_vect = vectorizer.transform(X_dev).toarray()\n",
    "X_test_vect = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96789b43-d589-429e-b0ac-a643429b1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = build_model(input_dim=X_train_vect.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f158563-849b-4296-9f0d-ec2c5b188d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38276c11-9c2b-4962-9e42-c032b11e4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6037 - loss: 5.7539 - val_accuracy: 0.9541 - val_loss: 1.9036\n",
      "Epoch 2/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8098 - loss: 1.6800 - val_accuracy: 0.9492 - val_loss: 1.0964\n",
      "Epoch 3/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 1.0320 - val_accuracy: 0.9526 - val_loss: 0.8019\n",
      "Epoch 4/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7559 - loss: 0.8037 - val_accuracy: 0.8688 - val_loss: 0.7155\n",
      "Epoch 5/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7499 - loss: 0.7402 - val_accuracy: 0.8778 - val_loss: 0.6966\n",
      "Epoch 6/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.7265 - val_accuracy: 0.9555 - val_loss: 0.6897\n",
      "Epoch 7/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8620 - loss: 0.7195 - val_accuracy: 0.9422 - val_loss: 0.6771\n",
      "Epoch 8/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8919 - loss: 0.7044 - val_accuracy: 0.9593 - val_loss: 0.6544\n",
      "Epoch 9/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.6804 - val_accuracy: 0.9634 - val_loss: 0.6310\n",
      "Epoch 10/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.6631 - val_accuracy: 0.9643 - val_loss: 0.6109\n",
      "Epoch 11/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9247 - loss: 0.6424 - val_accuracy: 0.9695 - val_loss: 0.5924\n",
      "Epoch 12/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.6268 - val_accuracy: 0.9700 - val_loss: 0.5776\n",
      "Epoch 13/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9289 - loss: 0.6146 - val_accuracy: 0.9736 - val_loss: 0.5624\n",
      "Epoch 14/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.6002 - val_accuracy: 0.9728 - val_loss: 0.5493\n",
      "Epoch 15/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.5874 - val_accuracy: 0.9736 - val_loss: 0.5373\n",
      "Epoch 16/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.5767 - val_accuracy: 0.9721 - val_loss: 0.5264\n",
      "Epoch 17/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9435 - loss: 0.5668 - val_accuracy: 0.9724 - val_loss: 0.5154\n",
      "Epoch 18/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9465 - loss: 0.5524 - val_accuracy: 0.9728 - val_loss: 0.5062\n",
      "Epoch 19/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9449 - loss: 0.5459 - val_accuracy: 0.9773 - val_loss: 0.4953\n",
      "Epoch 20/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9472 - loss: 0.5346 - val_accuracy: 0.9778 - val_loss: 0.4861\n",
      "Epoch 21/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9508 - loss: 0.5291 - val_accuracy: 0.9778 - val_loss: 0.4776\n",
      "Epoch 22/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.5182 - val_accuracy: 0.9780 - val_loss: 0.4686\n",
      "Epoch 23/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9524 - loss: 0.5111 - val_accuracy: 0.9787 - val_loss: 0.4604\n",
      "Epoch 24/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9523 - loss: 0.5016 - val_accuracy: 0.9798 - val_loss: 0.4534\n",
      "Epoch 25/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9538 - loss: 0.4998 - val_accuracy: 0.9795 - val_loss: 0.4451\n",
      "Epoch 26/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9566 - loss: 0.4864 - val_accuracy: 0.9797 - val_loss: 0.4389\n",
      "Epoch 27/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9575 - loss: 0.4817 - val_accuracy: 0.9809 - val_loss: 0.4318\n",
      "Epoch 28/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9552 - loss: 0.4766 - val_accuracy: 0.9808 - val_loss: 0.4252\n",
      "Epoch 29/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9592 - loss: 0.4698 - val_accuracy: 0.9802 - val_loss: 0.4213\n",
      "Epoch 30/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9614 - loss: 0.4602 - val_accuracy: 0.9811 - val_loss: 0.4144\n",
      "Epoch 31/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9607 - loss: 0.4555 - val_accuracy: 0.9807 - val_loss: 0.4086\n",
      "Epoch 32/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9604 - loss: 0.4513 - val_accuracy: 0.9814 - val_loss: 0.4030\n",
      "Epoch 33/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9602 - loss: 0.4484 - val_accuracy: 0.9823 - val_loss: 0.3967\n",
      "Epoch 34/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9628 - loss: 0.4406 - val_accuracy: 0.9821 - val_loss: 0.3909\n",
      "Epoch 35/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9671 - loss: 0.4306 - val_accuracy: 0.9837 - val_loss: 0.3863\n",
      "Epoch 36/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9611 - loss: 0.4317 - val_accuracy: 0.9832 - val_loss: 0.3816\n",
      "Epoch 37/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9640 - loss: 0.4263 - val_accuracy: 0.9833 - val_loss: 0.3764\n",
      "Epoch 38/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9630 - loss: 0.4222 - val_accuracy: 0.9848 - val_loss: 0.3718\n",
      "Epoch 39/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9660 - loss: 0.4144 - val_accuracy: 0.9830 - val_loss: 0.3701\n",
      "Epoch 40/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.4104 - val_accuracy: 0.9842 - val_loss: 0.3643\n",
      "Epoch 41/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.4025 - val_accuracy: 0.9834 - val_loss: 0.3625\n",
      "Epoch 42/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9669 - loss: 0.4053 - val_accuracy: 0.9853 - val_loss: 0.3566\n",
      "Epoch 43/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9658 - loss: 0.4018 - val_accuracy: 0.9832 - val_loss: 0.3527\n",
      "Epoch 44/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9674 - loss: 0.3959 - val_accuracy: 0.9849 - val_loss: 0.3480\n",
      "Epoch 45/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9687 - loss: 0.3913 - val_accuracy: 0.9844 - val_loss: 0.3464\n",
      "Epoch 46/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9676 - loss: 0.3880 - val_accuracy: 0.9860 - val_loss: 0.3426\n",
      "Epoch 47/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.3809 - val_accuracy: 0.9858 - val_loss: 0.3380\n",
      "Epoch 48/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9711 - loss: 0.3788 - val_accuracy: 0.9860 - val_loss: 0.3363\n",
      "Epoch 49/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.3816 - val_accuracy: 0.9863 - val_loss: 0.3319\n",
      "Epoch 50/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9726 - loss: 0.3719 - val_accuracy: 0.9857 - val_loss: 0.3286\n",
      "Epoch 51/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9695 - loss: 0.3733 - val_accuracy: 0.9846 - val_loss: 0.3274\n",
      "Epoch 52/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9720 - loss: 0.3690 - val_accuracy: 0.9870 - val_loss: 0.3232\n",
      "Epoch 53/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9725 - loss: 0.3659 - val_accuracy: 0.9865 - val_loss: 0.3217\n",
      "Epoch 54/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9703 - loss: 0.3607 - val_accuracy: 0.9870 - val_loss: 0.3179\n",
      "Epoch 55/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9719 - loss: 0.3587 - val_accuracy: 0.9873 - val_loss: 0.3147\n",
      "Epoch 56/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.3547 - val_accuracy: 0.9872 - val_loss: 0.3122\n",
      "Epoch 57/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9708 - loss: 0.3531 - val_accuracy: 0.9878 - val_loss: 0.3096\n",
      "Epoch 58/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9721 - loss: 0.3521 - val_accuracy: 0.9870 - val_loss: 0.3082\n",
      "Epoch 59/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9737 - loss: 0.3474 - val_accuracy: 0.9880 - val_loss: 0.3045\n",
      "Epoch 60/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.3406 - val_accuracy: 0.9874 - val_loss: 0.3062\n",
      "Epoch 61/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9741 - loss: 0.3435 - val_accuracy: 0.9871 - val_loss: 0.3013\n",
      "Epoch 62/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9748 - loss: 0.3374 - val_accuracy: 0.9882 - val_loss: 0.2985\n",
      "Epoch 63/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.3397 - val_accuracy: 0.9880 - val_loss: 0.2957\n",
      "Epoch 64/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.3348 - val_accuracy: 0.9874 - val_loss: 0.2950\n",
      "Epoch 65/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9735 - loss: 0.3371 - val_accuracy: 0.9882 - val_loss: 0.2902\n",
      "Epoch 66/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9732 - loss: 0.3316 - val_accuracy: 0.9880 - val_loss: 0.2901\n",
      "Epoch 67/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9746 - loss: 0.3282 - val_accuracy: 0.9878 - val_loss: 0.2881\n",
      "Epoch 68/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9742 - loss: 0.3279 - val_accuracy: 0.9886 - val_loss: 0.2844\n",
      "Epoch 69/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9745 - loss: 0.3235 - val_accuracy: 0.9886 - val_loss: 0.2844\n",
      "Epoch 70/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9733 - loss: 0.3266 - val_accuracy: 0.9883 - val_loss: 0.2822\n",
      "Epoch 71/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9753 - loss: 0.3232 - val_accuracy: 0.9892 - val_loss: 0.2795\n",
      "Epoch 72/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.3191 - val_accuracy: 0.9871 - val_loss: 0.2786\n",
      "Epoch 73/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9771 - loss: 0.3143 - val_accuracy: 0.9892 - val_loss: 0.2767\n",
      "Epoch 74/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.3151 - val_accuracy: 0.9868 - val_loss: 0.2763\n",
      "Epoch 75/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9762 - loss: 0.3152 - val_accuracy: 0.9872 - val_loss: 0.2738\n",
      "Epoch 76/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9756 - loss: 0.3095 - val_accuracy: 0.9885 - val_loss: 0.2734\n",
      "Epoch 77/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.3096 - val_accuracy: 0.9873 - val_loss: 0.2720\n",
      "Epoch 78/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.3053 - val_accuracy: 0.9890 - val_loss: 0.2679\n",
      "Epoch 79/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.3044 - val_accuracy: 0.9893 - val_loss: 0.2656\n",
      "Epoch 80/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9786 - loss: 0.3009 - val_accuracy: 0.9889 - val_loss: 0.2640\n",
      "Epoch 81/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9787 - loss: 0.3011 - val_accuracy: 0.9896 - val_loss: 0.2641\n",
      "Epoch 82/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.3030 - val_accuracy: 0.9886 - val_loss: 0.2639\n",
      "Epoch 83/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.2949 - val_accuracy: 0.9892 - val_loss: 0.2609\n",
      "Epoch 84/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.2969 - val_accuracy: 0.9894 - val_loss: 0.2576\n",
      "Epoch 85/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9767 - loss: 0.2970 - val_accuracy: 0.9899 - val_loss: 0.2570\n",
      "Epoch 86/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.2925 - val_accuracy: 0.9897 - val_loss: 0.2572\n",
      "Epoch 87/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.2924 - val_accuracy: 0.9904 - val_loss: 0.2548\n",
      "Epoch 88/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.2939 - val_accuracy: 0.9873 - val_loss: 0.2570\n",
      "Epoch 89/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.2913 - val_accuracy: 0.9890 - val_loss: 0.2525\n",
      "Epoch 90/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9778 - loss: 0.2910 - val_accuracy: 0.9884 - val_loss: 0.2512\n",
      "Epoch 91/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9763 - loss: 0.2910 - val_accuracy: 0.9902 - val_loss: 0.2503\n",
      "Epoch 92/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.2830 - val_accuracy: 0.9892 - val_loss: 0.2497\n",
      "Epoch 93/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9793 - loss: 0.2842 - val_accuracy: 0.9891 - val_loss: 0.2462\n",
      "Epoch 94/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.2868 - val_accuracy: 0.9890 - val_loss: 0.2482\n",
      "Epoch 95/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9802 - loss: 0.2842 - val_accuracy: 0.9906 - val_loss: 0.2444\n",
      "Epoch 96/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9805 - loss: 0.2805 - val_accuracy: 0.9894 - val_loss: 0.2436\n",
      "Epoch 97/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9779 - loss: 0.2803 - val_accuracy: 0.9903 - val_loss: 0.2429\n",
      "Epoch 98/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.2787 - val_accuracy: 0.9906 - val_loss: 0.2406\n",
      "Epoch 99/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.2796 - val_accuracy: 0.9900 - val_loss: 0.2397\n",
      "Epoch 100/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.2782 - val_accuracy: 0.9897 - val_loss: 0.2394\n",
      "Epoch 101/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.2721 - val_accuracy: 0.9909 - val_loss: 0.2388\n",
      "Epoch 102/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9820 - loss: 0.2699 - val_accuracy: 0.9904 - val_loss: 0.2387\n",
      "Epoch 103/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9816 - loss: 0.2715 - val_accuracy: 0.9908 - val_loss: 0.2369\n",
      "Epoch 104/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9788 - loss: 0.2754 - val_accuracy: 0.9906 - val_loss: 0.2356\n",
      "Epoch 105/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9804 - loss: 0.2713 - val_accuracy: 0.9906 - val_loss: 0.2342\n",
      "Epoch 106/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9806 - loss: 0.2692 - val_accuracy: 0.9905 - val_loss: 0.2326\n",
      "Epoch 107/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.2674 - val_accuracy: 0.9904 - val_loss: 0.2327\n",
      "Epoch 108/150\n",
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.2658 - val_accuracy: 0.9915 - val_loss: 0.2327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25b9901ee00>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train_vect, y_train,\n",
    "    validation_data=(X_dev_vect, y_dev),\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight = {0: 1.0, 1: 1.1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71d8db63-3364-41ee-94c3-fce9c19244da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2348\n",
      "           1       0.98      0.99      0.99      2142\n",
      "\n",
      "    accuracy                           0.99      4490\n",
      "   macro avg       0.99      0.99      0.99      4490\n",
      "weighted avg       0.99      0.99      0.99      4490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final Testing Loop — Evaluation on Test Set\n",
    "print(\"\\nFinal Evaluation on Test Set:\")\n",
    "y_pred_prob = model.predict(X_test_vect)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75ccaef8-ee07-4350-9599-e668ed285bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/vectorizer.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model and vectorizer\n",
    "model.save(\"../models/model.keras\")\n",
    "joblib.dump(vectorizer, \"../models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37df833b-9b2c-46ff-8876-b1570567716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load for inference\n",
    "model = load_model(\"../models/model.keras\")\n",
    "vectorizer = joblib.load(\"../models/vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8ff5a98-b255-4c4d-9a96-b6192050bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inference on Real-world Samples:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Breaking: Prime Minister announces new economic reforms. -> Real (0.58)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Aliens landed in Ohio according to anonymous sources. -> Fake (0.05)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "The COVID-19 vaccine rollout continues across Europe. -> Fake (0.08)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "NASA confirms water on the Moon. -> Fake (0.16)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Donald Trump wins the presidential election again. -> Real (0.59)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "India is a country. -> Fake (0.11)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "White House, Congress prepare for talks on spending, immigration -> Fake (0.35)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Scientists discover a way to live forever using jellyfish DNA. -> Fake (0.05)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Stocks crash after rumors of global economic collapse. -> Fake (0.20)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "New study shows chocolate improves brain function. -> Fake (0.11)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Vaccine causes telepathic powers in 1% of recipients, claims study. -> Fake (0.09)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "UN convenes emergency session on climate change crisis. -> Fake (0.11)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Elon Musk launches reusable rocket that lands on Mars. -> Fake (0.13)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Government passes bill banning all smartphones by 2025. -> Fake (0.23)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Earthquake hits Tokyo, no casualties reported. -> Fake (0.21)\n",
      "\n",
      "Sample features:\n",
      "['00' '000' '000 people' '10' '10 000' '10 percent' '10 years' '100'\n",
      " '100 000' '11' '12' '120' '13' '14' '15' '150' '16' '17' '18' '19']\n",
      "Total features in vocab: 5000\n"
     ]
    }
   ],
   "source": [
    "# Real-world examples\n",
    "print(\"\\nInference on Real-world Samples:\")\n",
    "\n",
    "examples = [\n",
    "    (\"Breaking: Prime Minister announces new economic reforms.\", \"politicsNews\"),  # Real\n",
    "    (\"Aliens landed in Ohio according to anonymous sources.\", \"worldnews\"),        # Fake\n",
    "    (\"The COVID-19 vaccine rollout continues across Europe.\", \"healthNews\"),       # Real\n",
    "    (\"NASA confirms water on the Moon.\", \"scienceNews\"),                           # Real\n",
    "    (\"Donald Trump wins the presidential election again.\", \"politicsNews\"),        # Fake/Unlikely\n",
    "    (\"India is a country.\", \"worldnews\"),                                          # Generic/ambiguous\n",
    "    (\"White House, Congress prepare for talks on spending, immigration\", \"politicsNews\"),  # Real\n",
    "    (\"Scientists discover a way to live forever using jellyfish DNA.\", \"scienceNews\"),     # Likely Fake\n",
    "    (\"Stocks crash after rumors of global economic collapse.\", \"businessNews\"),            # Possibly Fake\n",
    "    (\"New study shows chocolate improves brain function.\", \"healthNews\"),                  # Real-sounding\n",
    "    (\"Vaccine causes telepathic powers in 1% of recipients, claims study.\", \"healthNews\"), # Fake\n",
    "    (\"UN convenes emergency session on climate change crisis.\", \"worldnews\"),             # Real\n",
    "    (\"Elon Musk launches reusable rocket that lands on Mars.\", \"scienceNews\"),            # Partially Fake (as of now)\n",
    "    (\"Government passes bill banning all smartphones by 2025.\", \"politicsNews\"),          # Likely Fake\n",
    "    (\"Earthquake hits Tokyo, no casualties reported.\", \"worldnews\")                       # Real\n",
    "]\n",
    "\n",
    "\n",
    "for title, subject in examples:\n",
    "    combined_text = f\"{title} [SEP] {subject}\"\n",
    "    X_ex = vectorizer.transform([combined_text])\n",
    "    pred_prob = model.predict(X_ex.toarray())[0][0]\n",
    "\n",
    "    # Use threshold tuned on dev set if available, else fallback\n",
    "    threshold = 0.4  \n",
    "    label = \"Real\" if pred_prob >= threshold else \"Fake\"\n",
    "\n",
    "    print(f\"{title} -> {label} ({pred_prob:.2f})\")\n",
    "\n",
    "# Check vocab info\n",
    "print(\"\\nSample features:\")\n",
    "print(vectorizer.get_feature_names_out()[:20])\n",
    "print(\"Total features in vocab:\", len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "18639ab3-ac7e-4bf2-840e-8f6bbf1c7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m663/663\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step\n",
      "\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     11095\n",
      "           1       0.99      1.00      0.99     10119\n",
      "\n",
      "    accuracy                           0.99     21214\n",
      "   macro avg       0.99      0.99      0.99     21214\n",
      "weighted avg       0.99      0.99      0.99     21214\n",
      "\n",
      "\u001b[1m600/600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step\n",
      "\n",
      "Dev Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     10038\n",
      "           1       0.99      0.99      0.99      9156\n",
      "\n",
      "    accuracy                           0.99     19194\n",
      "   macro avg       0.99      0.99      0.99     19194\n",
      "weighted avg       0.99      0.99      0.99     19194\n",
      "\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step\n",
      "\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      2348\n",
      "           1       0.98      0.99      0.99      2142\n",
      "\n",
      "    accuracy                           0.99      4490\n",
      "   macro avg       0.99      0.99      0.99      4490\n",
      "weighted avg       0.99      0.99      0.99      4490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train predictions\n",
    "y_train_pred = (model.predict(X_train_vect) > 0.5).astype(int)\n",
    "print(\"\\nTrain Classification Report:\")\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "# Dev predictions\n",
    "y_dev_pred = (model.predict(X_dev_vect) > 0.5).astype(int)\n",
    "print(\"\\nDev Classification Report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "\n",
    "# Test predictions\n",
    "y_test_pred = (model.predict(X_test_vect) > 0.5).astype(int)\n",
    "print(\"\\nTest Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaca7d45-ea49-40de-b2ab-7015a99430d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
